[
  {
    "objectID": "notebooks/Chapter 02 - Small Worlds and Large Worlds.html",
    "href": "notebooks/Chapter 02 - Small Worlds and Large Worlds.html",
    "title": "Chapter 2 – Small Worlds and Large Worlds",
    "section": "",
    "text": "Set-up\n\nusing Plots\nusing Colors\nusing StatsPlots\nusing StatsBase\nusing DataFrames\nusing Distributions\nusing SpecialFunctions\n\ndefault(\n  labels=false, fontfamily=\"sans-serif\", titlefontsize=10, labelfontsize=8,\n  legendfontsize=5, color=:steelblue2, fillcolor=:steelblue2)\n\nCode 2.1\n\nsamp = [\"W\",\"L\",\"W\",\"W\",\"W\",\"L\",\"W\",\"L\",\"W\"]\nW = sum(samp .== \"W\")\nL = sum(samp .== \"L\")\np = collect(0:0.25:1) # proportions W\nways = map( x -&gt; (x*4)^W * ((1-x)*4)^L, p)\nprob = ways ./ sum(ways)\nhcat(p, ways, prob)\n\n5×3 Matrix{Float64}:\n 0.0     0.0  0.0\n 0.25   27.0  0.0212934\n 0.5   512.0  0.403785\n 0.75  729.0  0.574921\n 1.0     0.0  0.0\n\n\nCode 2.2\n\nbar(p, prob, xlabel=\"proportion water\", ylabel=\"probability\", legend=false)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.3\n\nsamp = [\"W\",\"L\",\"W\",\"W\",\"W\",\"L\",\"W\",\"L\",\"W\"]\nW = sum(samp .== \"W\")\nL = sum(samp .== \"L\")\nposs = collect(0:0.25:1) # proportions W\nways = map( x -&gt; (x)^W * (1-x)^L, poss)\npost = ways ./ sum(ways)\nhcat(poss, ways, post)\n\n5×3 Matrix{Float64}:\n 0.0   0.0          0.0\n 0.25  0.000102997  0.0212934\n 0.5   0.00195312   0.403785\n 0.75  0.00278091   0.574921\n 1.0   0.0          0.0\n\n\nCode 2.4\n\nfunction compute_posterior( the_sample , poss )\n  W = sum(the_sample .== \"W\")\n  L = sum(the_sample .== \"L\")\n  ways = map( x -&gt; (x)^W * (1-x)^L, poss)\n  post = ways ./ sum(ways)\n  DataFrame(\n    poss=poss, \n    ways=ways, \n    post=round.(post, digits=3))\nend\n\ncompute_posterior (generic function with 1 method)\n\n\nCode 2.5\n\nthe_sample = [\"W\",\"L\",\"W\",\"W\",\"W\",\"L\",\"W\",\"L\",\"W\"]\nthe_possibilities = collect(0:0.25:1)\ncompute_posterior( the_sample , the_possibilities )\n\n5×3 DataFrame\n\n\n\nRow\nposs\nways\npost\n\n\n\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n0.0\n0.0\n0.0\n\n\n2\n0.25\n0.000102997\n0.021\n\n\n3\n0.5\n0.00195312\n0.404\n\n\n4\n0.75\n0.00278091\n0.575\n\n\n5\n1.0\n0.0\n0.0\n\n\n\n\n\n\nCode 2.6\n\ncollect(range(0,1, length=11))\n\n11-element Vector{Float64}:\n 0.0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n 0.8\n 0.9\n 1.0\n\n\nCode 2.7\n\nthe_possibilities = collect(range(0,1, length=11))\ncompute_posterior( the_sample, the_possibilities)\n\n11×3 DataFrame\n\n\n\nRow\nposs\nways\npost\n\n\n\nFloat64\nFloat64\nFloat64\n\n\n\n\n1\n0.0\n0.0\n0.0\n\n\n2\n0.1\n7.29e-7\n0.0\n\n\n3\n0.2\n3.2768e-5\n0.003\n\n\n4\n0.3\n0.000250047\n0.021\n\n\n5\n0.4\n0.000884736\n0.074\n\n\n6\n0.5\n0.00195312\n0.164\n\n\n7\n0.6\n0.00298598\n0.251\n\n\n8\n0.7\n0.00317652\n0.267\n\n\n9\n0.8\n0.00209715\n0.176\n\n\n10\n0.9\n0.000531441\n0.045\n\n\n11\n1.0\n0.0\n0.0\n\n\n\n\n\n\nCode 2.8\n\n# 10 sided die\nthe_possibilities = collect(range(0, 1 , length=10+1))\npost = compute_posterior( the_sample , the_possibilities)\nfig2_6_left = bar(\n  the_possibilities, post.post, fillcolor=:steelblue2, legend=false, ylim=(0,0.3),\n  xlabel=\"proportion water\", ylabel=\"probability\",\n  title=string(length(the_possibilities), \" possibilities\"))\n\n## NOT IN BOOK -- Reproduce Fig 2.6\n# 20 sided die\nthe_possibilities = collect(range(0 , 1, length=20+1))\npost = compute_posterior( the_sample , the_possibilities)\nfig2_6_right = bar(\n  the_possibilities, post.post, fillcolor=:tomato, legend=false, ylim=(0,0.3),\n  xlabel=\"proportion water\", ylabel=\"probability\", \n  title=string(length(the_possibilities), \" possibilities\"))\n\ndisplay(plot(fig2_6_left, fig2_6_right, layout=(1,2), size = (600,300), linecolor=nothing))\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.9\n\nfunction compute_posterior2(p, the_sample, the_prior)\n    W = sum(the_sample .== \"W\")\n    L = sum(the_sample .== \"L\")\n    W_prior = sum(the_prior .== \"W\")\n    L_prior = sum(the_prior .== \"L\")\n    pdf(Beta(W + W_prior + 1, L + L_prior + 1), p)\nend\n\n# Sample data\nthe_sample = [\"W\",\"L\",\"W\",\"W\",\"W\",\"L\",\"W\",\"L\",\"W\"]\n\n# Generate a vector of x values\nx = 0:0.01:1\n\n# Single Plot (bottom right of fig 2.7)\npost = compute_posterior2(x, the_sample, [])\nplot(\n      x, y=post, linewidth=2,\n      xlabel=\"\", ylabel=\"\", yticks = [],\n      legend=:outertop, legendfontsize=8, \n      legendforegroundcolor=nothing,\n      legendbackgroundcolor=nothing,\n    )\n\n## NOT IN BOOK -- Reproduce Fig 2.7\n\n# Create a 3x3 array to store individual plots\nn = length(the_sample)\nplots = Plots.Plot[plot(title=\"Plot $i\") for i in 1:n]\n\n# iterate through the sample one at a time, keeping a vector prior obs\nfor i in 1:n\n    the_prior = the_sample[1:(i-1)]\n    y_post = compute_posterior2(x, the_sample[1:i], the_prior)\n    y_prior = compute_posterior2(x, the_sample[1:i-1], the_prior[1:i-2])\n    label = join(the_sample[1:i], \" \")\n    col = the_sample[i] == \"W\" ? :steelblue2 : :tomato\n    p = plot(\n      x, y_post, color=col, linewidth=2,\n      label=label, xlabel=\"\", ylabel=\"\", yticks = [],\n      legend=:outertop, legendfontsize=8, \n      legendforegroundcolor=nothing,\n      legendbackgroundcolor=nothing,\n    )\n    plots[i] = plot!(\n      p, x, y_prior, color = :black, linestyle = :dash, linewidth=1.5)\nend\n\n# Splat (...) `plots` into a single 3x3 grid plot (fig2_7)\nfig2_7 = plot(plots..., layout=(3,3), size = (600,600));\ndisplay(fig2_7)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.10\n\npost_samples = rand(Beta(6+1, 3+1), 1000);\n\nCode 2.11\n\ndensity(post_samples, linewidth=3, linecolor=:tomato,\n  xlabel=\"proportion water\", label=\"Density\")\n\n# Overlay the beta distribution curve\nx_values = 0:0.01:1\ny_values = pdf(Beta(6 + 1, 3 + 1), x_values)\nplot!(x_values, y_values, linestyle=:dash, linewidth=3, color=:black,\n  label=\"Beta(7, 4)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.12\n\ndensity(post_samples, linewidth=3, linecolor=:tomato,\n  bandwidth=.005, # smaller bandwith -&gt; more wiggly\n  xlabel=\"proportion water\", label=\"Density\", title=\"Wiggle Wiggle\")\n\n# Overlay the beta distribution curve\nx_values = 0:0.01:1\ny_values = pdf(Beta(6 + 1, 3 + 1), x_values)\nplot!(x_values, y_values, linestyle=:dash, linewidth=3, color=:black,\n  label=\"Beta(7, 4)\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.13\nNeed to define the precis function.\nHacked from precis.jl in `StatisticalRethinking.jl\n\nusing StatsBase: Histogram\nusing Statistics: quantile\nusing PrettyTables: pretty_table\n\nconst BARS = collect(\"▁▂▃▄▅▆▇█\")\n\nfunction unicode_histogram(data, nbins = 12)\n    # @show data\n    f = fit(Histogram, data, nbins = nbins)  # nbins: more like a guideline than a rule, really\n    # scale weights between 1 and 8 (length(BARS)) to fit the indices in BARS\n    # eps is needed so indices are in the interval [0, 8) instead of [0, 8] which could\n    # result in indices 0:8 which breaks things\n    scaled = f.weights .* (length(BARS) / maximum(f.weights) - eps())\n    indices = floor.(Int, scaled) .+ 1\n    return join((BARS[i] for i in indices))\nend\n\nfunction precis(x; digits = 4, a = 0.11)\n    d = DataFrame()\n    df = isa(x, DataFrame) ? x : DataFrame( x = x )\n    cols = collect.(skipmissing.(eachcol(df)))\n    d.param = names(df)\n    d.mean = mean.(cols)\n    d.std = std.(cols)\n    quants = quantile.(cols, ([a/2, 0.5, 1-a/2], ))\n    quants = hcat(quants...)\n    d[:, \"5.5%\"] = quants[1,:]\n    d[:, \"50%\"] = quants[2,:]\n    d[:, \"94.5%\"] = quants[3,:]\n    d.histogram = unicode_histogram.(cols, min(size(df, 1), 12))\n\n    for col in [\"mean\", \"std\", \"5.5%\", \"50%\", \"94.5%\"]\n        d[:, col] .= round.(d[:, col], digits = digits)\n    end\n\n    display(pretty_table(d))\nend\n\nWARNING: redefinition of constant Main.BARS. This may fail, cause incorrect answers, or produce other errors.\n\n\nprecis (generic function with 1 method)\n\n\n\nprecis( post_samples )\n\n┌────────┬─────────┬─────────┬─────────┬─────────┬─────────┬───────────┐\n│  param │    mean │     std │    5.5% │     50% │   94.5% │ histogram │\n│ String │ Float64 │ Float64 │ Float64 │ Float64 │ Float64 │    String │\n├────────┼─────────┼─────────┼─────────┼─────────┼─────────┼───────────┤\n│      x │  0.6346 │  0.1391 │  0.4012 │  0.6416 │  0.8449 │ ▁▁▂▄██▇▄▁ │\n└────────┴─────────┴─────────┴─────────┴─────────┴─────────┴───────────┘\n\n\nnothing\n\n\nCode 2.14\n\ndensity(post_samples, linewidth=3, linecolor=:tomato,\n  bandwidth=.005, # smaller bandwith -&gt; more wiggly\n  xlabel=\"proportion water\", label=\"Density\")\n\n# Overlay the beta distribution curve\nx_values = 0:0.01:1\ny_values = pdf(Beta(6 + 1, 3 + 1), x_values)\nplot!(x_values, y_values, linestyle=:dash, linewidth=3, color=:black,\n  label=\"Beta(7, 4)\")\npp = [.4, .64, .84]\nbb = pdf(Beta(7,4), pp)\nbar!(pp, bb, bar_width=.005, fillcolor=:black, linecolor=nothing)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.15\n\nsample([\"W\", \"L\"], AnalyticWeights([.7,.3]), 9, replace=true)\n\n9-element Vector{String}:\n \"W\"\n \"L\"\n \"L\"\n \"L\"\n \"W\"\n \"L\"\n \"W\"\n \"W\"\n \"W\"\n\n\nCode 2.16\n\nfunction sim_globe(p = 0.7, N = 9)\n  sample([\"W\", \"L\"], AnalyticWeights([p,1-p]), N, replace=true)\nend\n\nsim_globe (generic function with 3 methods)\n\n\nCode 2.17\n\nsim_globe(0.1, 10)\n\n10-element Vector{String}:\n \"L\"\n \"L\"\n \"L\"\n \"L\"\n \"W\"\n \"L\"\n \"L\"\n \"L\"\n \"L\"\n \"L\"\n\n\nCode 2.18\n\npred_01 = [ sum(sim_globe(0.1, 10) .== \"W\") for _ in 1:10000 ];\n\nCode 2.19\n\nbar( sort( countmap( pred_01 ) ), linecolor=nothing, bar_width=.25,\n     xlabel=\"number of W\", ylabel=\"count\", title=\"p=0.1\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# NOT IN BOOK -- Add additional Plots\npred_25 = [ sum(sim_globe(0.25, 10) .== \"W\") for _ in 1:10000 ]\npred_60 = [ sum(sim_globe(0.6, 10) .== \"W\") for _ in 1:10000 ]\nplot1 = bar( sort( countmap( pred_25 ) ), \n      linecolor=nothing, bar_width=.25, title=\"p=0.25\")\nplot2 = bar( sort( countmap( pred_60 ) ), \n      linecolor=nothing, bar_width=.25, title=\"p=0.6\")\nplot(plot1, plot2, layout=(1,2), xlabel=\"number of W\", ylabel=\"count\" )\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.20\n\np = .64\npred_64 = [ sum(sim_globe(0.64, 10) .== \"W\") for _ in 1:10000 ];\nbar( sort( countmap( pred_64 ) ), fillcolor=:black, linecolor=nothing, bar_width=.25,\n     xlabel=\"number of W\", ylabel=\"count\", title=\"p=0.64\")\n\npost_samples = rand(Beta(6+1, 3+1), 10000);\npred_post = [ sum( sim_globe(p, 10) .== \"W\" ) for p in post_samples];\ntab_post = sort(countmap(pred_post));\nbar!( tab_post, fillcolor=:steelblue2, linecolor=nothing, bar_width=.125)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.21\n\nfunction sim_globe2( p=0.7, N=9 , x=0.1 )\n  true_sample = sample([\"W\", \"L\"], AnalyticWeights([p,1-p]), N, replace=true)\n  obs_sample = ifelse.(\n    rand(Uniform(), N) .&lt; x ,\n    ifelse.( true_sample .== \"W\" , [\"L\"] , [\"W\"]),\n    true_sample)\n  obs_sample\nend\n\nsim_globe2 (generic function with 4 methods)\n\n\nCode 2.22\n\n# code for the normalizing constant\nfunction ibeta( x , a , b ) \n  # (R =&gt; julia)\n  ## pbeta(x, a, b) =&gt; cdf(Beta(a,b), x)\n  ## pbeta(x, a, b, log.p = TRUE) =&gt; log(cdf(Beta(a,b), x))\n  ## lbeta(a,b) =&gt; logbeta(a,b)\n  exp( log(cdf(Beta(a, b), x)) + logbeta(a,b) )\nend\n\nfunction Z( x, W , L )\n  ( ibeta( 1-x , L+1, W+1 ) - ibeta( x , L+1, W+1 ) ) / ( 1-2*x )\nend\n\n# data\nW = 6\nL = 3\n\nx_values = 0:0.01:1\ny_values = pdf(Beta(W + 1, L + 1), x_values)\nplot(x_values, y_values, linewidth=3, color=:black,\n  label=\"Beta(7, 4)\", xlabel = \"proportion of water\",\n  ylabel=\"posterior probability\")\n# new misclassification posterior\nxe = 0.1\n# there is no `curve` function so we generate a function and broadcast\nfunction misclass_post( x , xe , W , L )\n  (1/Z(xe,W,L)) * (x*(1-xe)+(1-x)*xe)^W * ((1-x)*(1-xe)+x*xe)^L\nend\ny_values = misclass_post.(x_values, xe, W, L)\nplot!(x_values, y_values, linewidth=3, color=:red)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode 2.23\n\nfunction misclass_post( x , xe , W , L )\n  (1/Z(xe,W,L)) * (x*(1-xe)+(1-x)*xe)^W * ((1-x)*(1-xe)+x*xe)^L\nend\n\n# port function `rethinking::grau()`\nfunction grau(alpha=0.5)\n  # http://juliagraphics.github.io/Colors.jl/stable/constructionandconversion/#Color-Parsing\n  coloralpha(colorant\"black\", alpha)\nend\n\nfunction plot_sim( p , N, xe )\n  sim_sample = sim_globe2( p , N , xe);\n  W = sum(sim_sample .== \"W\")\n  L = sum(sim_sample .== \"L\")\n  #\n  x_values = 0:0.01:1\n  y_values = pdf(Beta(W + 1, L + 1), x_values)\n  #\n  plot(x_values, y_values, linewidth=2, color=:black)\n  # new misclassification posterior\n  y_values = misclass_post.(x_values, xe, W, L)\n  vline!([0.7], color=grau(), linewidth=1)\n  plot!(x_values, y_values, linewidth=2, color=:red)\n  xlims!(.5, .85) # zoom in to make the subplots cleaner\nend\n\n# repeat the function a few times. observe how the new posterior, \n## which accounts for misclassification, is consistently closer to true p.\nplots = Plots.Plot[plot() for i in 1:9];\n\n# iterate through the sample one at a time, keeping a vector prior obs\np = 0.7\nN = Int(1e3)\nxe = 0.2\nfor i in 1:n\n    plots[i] = plot_sim(p,N,xe)\n    if i == 1\n      plot!(xlabel = \"proportion of water\", ylabel=\"posterior probability\")\n    elseif mod(i-1,3) != 0\n      plot!(yticks = [])\n    end\nend\n\n# Splat (...) `plots` into a single 3x3 grid plot (fig2_7)\nplot(plots..., layout=(3,3), size = (600,600), plot_title = \"Ignores Missclassification (black) vs Accounts (red)\", plot_titlefontsize=10)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking (3rd edition) with Julia",
    "section": "",
    "text": "Here my attempt to port the R code blocks from the draft 3rd edition of Richard McElreath’s amazing book, Statistical Rethinking, to the Julia programming language."
  },
  {
    "objectID": "index.html#contents",
    "href": "index.html#contents",
    "title": "Statistical Rethinking (3rd edition) with Julia",
    "section": "Contents",
    "text": "Contents\nMore chapters to come; updated most Wednesdays nights.\n\nChapter 2. Small Worlds and Large World"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "Notebooks",
    "section": "",
    "text": "Chapter 2 – Small Worlds and Large Worlds\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]